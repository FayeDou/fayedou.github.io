<!DOCTYPE HTML>
<!--
	Read Only by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Fei Dou</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Header -->
			<section id="header">
				<header>
					<span class="image avatar"><img src="images/sara2crop.jpeg" alt="" /></span>
					<h1 id="logo"><a href="#">Fei Dou</a></h1>
					<p>Ph.D. Candidate, ML / AI / IoT<br />
						University of Connecticut<br />
						</p>
				</header>
				<nav id="nav">
					<ul>
						<li><a href="#about" class="active">About</a></li>
						<li><a href="#news">News</a></li>
						<li><a href="#projects">Projects</a></li>
<!-- 						<li><a href="#media">Media</a></li> -->
						<li><a href="#publications">Publications</a></li>
						<li><a href="#teaching">Teaching</a></li>
						<li><a href="#talks">Talks</a></li>
						<li><a href="#cv">CV & Bio</a></li>
<!--						<li><a href="#slack">AI for Conservation Slack</a></li>-->
					</ul>
				</nav>
				<footer>
					<ul class="icons">
						<li><a href="mailto:beery@mit.edu" class="icon solid fa-envelope"><span class="label">Email</span></a></li>
						<li><a href="https://scholar.google.com/citations?user=Hbr4c10AAAAJ&hl=en&oi=ao" class="icon solid fa-graduation-cap"><span class="label">Google Scholar</span></a></li>
						<li><a href="https://twitter.com/sarameghanbeery" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
						
					</ul>
				</footer>
			</section>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">

						<!-- About -->
							<section id="about">
								<div class="image main" data-position="center">
									<img src="images/sara_field_work.jpeg" alt="" />
								</div>
								<div class="container">
									<header class="major">
										<h3>About</h3>
									</header>
																			
									<p>I am currently a final-year Ph.D. student in Computer Science and Engineering at the University of Connecticut in
										<a href="https://healthinfo.lab.uconn.edu/">Laboratory of Machine Learning & Health Informatics</a>, working on
										<b> Machine Learning (ML) </b> / <b>Artificial Intelligence (AI)</b> in the <b> Internet of Things (IoT)</b>
										supervised by Prof. <a href="https://jinbo-bi.uconn.edu/"><b>Jinbo Bi</b></a>. Before that, I was working on Underwater Acoustic Sensor Networks
										(UWSAN) in Tianjin University supervised by Prof. Zhigang Jin. I received M.S. degree and B.S. degree in Electrical Engineering.
										
										<p>My research interests include: Reinforcement Learning, Federated Learning, On-Device Learning, Computer Vision,
										Contrastive Learning, Representation Learning; Location-based Services (LBS), Edge Computing, Data Privacy, Remote Sensing Imagery,
										Smart City, Mobile Computing, Wireless Networks.</p>
									</div>
							</section>
						
						<!-- News -->
							<section id="news">
								<div class="container">
									<header class="major">
										<h3>News</h3>
									</header>

									<p>[2023/01] Our papers (two) are Under Review by IJCAI 2023.<p>
									<p>[2022/11] I am invited to give a talk on "Special Topic on Reinforcement Learning and its Applications" at University of Michigan-Dearborn.<p>
									<p>[2022/10] Our paper is Under Review by IEEE Internet of Things Journal (IOT-J).<p>
									<p>[2022/08] Our paper is Under Review by IEEE Internet of Things Journal (IOT-J).<p>
									</div>
							</section>
						


						<!-- Projects -->
							<section id="projects">
								<div class="container">
									<h3>Selected Projects</h3>

									<h4><u> Remote Sensing, Satellite/Aerial Imagery, Contrastive Learning, Computer Vision</u></h4>
									<div class="features">
										<article>
											<a href="" class="image"><img src="images/satellite-disaster.png" alt="" /></a>
											<div class="inner">
												<p><b>Latent Orthonormal Contrastive Learning in Disaster Damage Assessment Using Paired Remote Sensing Imagery</b><br>
													<b>Fei Dou</b>, Cameron Cianci, Jinbo Bi<br>
													<i>In Submission to ICCV 2023</i><br>

													A latent orthonormal contrastive learning approach is proposed to handle the high-resolution satellite/aerial imagery.

										                </p>
											</div>
										</article>

										<article>
											<a href="https://web.archive.org/web/20180404110509id_/http://www.engr.uconn.edu:80/~jil14036/paper/07868471.pdf" class="image"><img src="images/bi-sub-saliency.png" alt="" /></a>
											<div class="inner">
												<p><b>Bi-Subspace Saliency Detection</b><br>
													Jin Lu, <b>Fei Dou</b>, Chun-Hsi Huang<br>
													<i>CCWC 2017</i> <a href="https://web.archive.org/web/20180404110509id_/http://www.engr.uconn.edu:80/~jil14036/paper/07868471.pdf" target="_self">[paper]</a><br>
										        	A novel bi-subspace data-driven saliency detection model is proposed by consider the problem from subspace analysis
													to characterize the background and foreground.
												</p>

											</div>
										</article>
									</div>


									<h4><u> Location-based Services (LBS), Reinforcement Learning, Federated Learning </u></h4>
									<div class="features">


										<article>
											<a href="" class="image"><img src="images/perFedRL.png" alt="" /></a>
											<div class="inner">
												<p><b>On-device Indoor Positioning: A Federated Reinforcement Learning Approach with Heterogeneous Devices</b><br>
												   <b>Fei Dou</b>, Jin Lu, Tan Zhu, Jinbo Bi<br>
											           <i>Under Review by IEEE Internet of Things Journal (IOT-J)</i><br>
											           A personalized federated learning (FL) for reinforcement learning (RL) is proposed to automatically learn
													environmental dynamics by client-environment interactions via RL and cope with the diversity of client devices
													and their non-identical data distributions via personalized FL.
										                </p>
											</div>
										</article>
										<article>
											<a href="https://arxiv.org/abs/2112.05090" class="image"><img src="images/expanding.png" alt="" /></a>
											<div class="inner">
												<p><b>Extending the WILDS Benchmark for Unsupervised Adaptation</b><br>
												   Shiori Sagawa, Pang Wei Koh, Tony Lee, Irena Gao, Sang Michael Xie, Kendrick Shen, Ananya Kumar, Weihua Hu, Michihiro Yasunaga, Henrik Marklund, <b>Sara Beery</b>, Etienne David, Ian Stavness, Wei Guo, Jure Leskovec, Kate Saenko, Tatsunori Hashimoto, Sergey Levine, Chelsea Finn, Percy Liang<br>
											           ICLR 2022 (Oral)<br>
											           <a href="https://arxiv.org/abs/2112.05090" target="_self">[paper]</a><a href="https://github.com/p-lambda/wilds/releases/tag/v2.0.0" target="_self">[code/data]</a>
										                </p>
											</div>
										</article>
										<article>
											<a href="https://dl.acm.org/doi/fullHtml/10.1145/3466857" class="image"><img src="images/scaling_biodiversity.png" alt="" /></a>
											<div class="inner">
												<p><b>Scaling Biodiversity Monitoring for the Data Age</b><br>
												   <b>Sara Beery</b><br>
											           ACM XRDS 2021<br>
											           <a href="https://dl.acm.org/doi/pdf/10.1145/3466857" target="_self">[paper]</a>
										                </p>
											</div>
										</article>
										<article>
											<a href="http://proceedings.mlr.press/v139/koh21a/koh21a.pdf" class="image"><img src="images/wilds.png" alt="" /></a>
											<div class="inner">
												<p><b>Wilds: A benchmark of in-the-wild distribution shifts</b><br>
												Pang Wei Koh, Shiori Sagawa, Sang Michael Xie, Marvin Zhang, Akshay Balsubramani, Weihua Hu, Michihiro Yasunaga, Richard Lanas Phillips, Irena Gao, Tony Lee, Etienne David, Ian Stavness, Wei Guo, Berton Earnshaw, Imran Haque, <b>Sara Beery</b>, Jure Leskovec, Anshul Kundaje, Emma Pierson, Sergey Levine, Chelsea Finn, Percy Liang<br>
												ICLR 2021 (Oral)<br>
												<a href="http://proceedings.mlr.press/v139/koh21a/koh21a.pdf" target="_self">[paper]</a><a href="https://github.com/p-lambda/wilds" target="_self">[code/data]</a></p>
											</div>
										</article>
									</div>
									<h4><u> Underwater Acoustic Sensor Networks (UWASN), Medium Access Control (MAC) </u></h4>

									
									<div class="features">
										<article>
											<a href="https://arxiv.org/abs/2103.16483" class="image"><img src="images/newt.png" alt="" /></a>
											<div class="inner">
												<p><b>Benchmarking Representation Learning for Natural World Image Collections</b><br>
												Grant Van Horn, Elijah Cole, <b>Sara Beery</b>, Kimberly Wilber, Serge Belongie, and Oisin Mac Aodha<br>
												CVPR 2021 (Oral)<br>
												<a href="https://arxiv.org/abs/2103.16483" target="_self">[paper]</a><a href="https://github.com/visipedia/newt" target="_self">[code/data]</a><a href="https://youtu.be/JuPUvgSnK6A" target="_self">[video]</a></p>
											</div>
										</article>
										<article>
											<a href="https://arxiv.org/abs/2103.16483" class="image"><img src="images/sdm.png" alt="" /></a>
											<div class="inner">
												<p><b>Species Distribution Modeling for Machine Learning Practitioners: A Review</b><br>
												<b>Sara Beery</b>*, Elijah Cole*, Joseph Parker, Pietro Perona, Kevin Winner<br>
												ACM COMPASS 2021<br>
												<a href="https://arxiv.org/abs/2107.10400" target="_self">[paper]</a></p>
											</div>
										</article>
										<article>
											<a href="https://arxiv.org/abs/2106.15083" class="image"><img src="images/elephantbook.png" alt="" /></a>
											<div class="inner">
												<p><b>ElephantBook: A Semi-Automated Human-in-the-Loop System for Elephant Re-Identification</b><br>
												Peter Kulits, Jake Wall, Anka Bedetti, Michelle Henley, <b>Sara Beery</b><br>
												ACM COMPASS 2021<br>
												<a href="https://arxiv.org/abs/2106.15083" target="_self">[paper]</a></p>
											</div>
										</article>
										<article>
											<a href="https://arxiv.org/pdf/1910.09716" class="image"><img src="images/active.png" alt="" /></a>
											<div class="inner">
												<p><b>A Deep Active Learning System for Species Identification and Counting in Camera Trap Images</b><br>
												Mohammad Sadegh Norouzzadeh, Dan Morris, <b>Sara Beery</b>, Neel Joshi, Nebojsa Jojic, Jeff Clune<br>
												Methods in Ecology and Evolution 2021<br>
												<a href="https://arxiv.org/pdf/1910.09716" target="_self">[paper]</a></p>
											</div>
										</article>
										<article>
											<a href="https://arxiv.org/pdf/1910.09716" class="image"><img src="images/trout.png" alt="" /></a>
											<div class="inner">
												<p><b>Automated Salmonid Counting in Sonar Data</b><br>
											        Peter Kulits, Angelina Pan, <b>Sara M Beery</b>, Erik Young, Pietro Perona, Grant Van Horn<br>
												Climate Change AI at NeurIPS 2020<br>
												<a href="https://www.climatechange.ai/papers/neurips2020/54.html" target="_self">[paper]</a><a href="https://slideslive.com/38942126" target="_self">[video]</a></p>
											</div>
										</article>
										<article>
											<a href="https://arxiv.org/abs/1912.03538" class="image"><img src="images/context-rcnn.png" alt="" /></a>
											<div class="inner">
												<p><b>Context R-CNN: Long Term Temporal Context for Per-Camera Object Detection</b><br>
												<b>Sara Beery</b>, Guanhang Wu, Vivek Rathod, Ronny Votel, Jonathan Huang<br>
												CVPR 2020<br>
												<a href="https://arxiv.org/abs/1912.03538" target="_self">[paper]</a><a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/context_rcnn.md" target="_self">[code]</a><a href="https://www.youtube.com/watch?v=fxLwzn6vyo4" target="_self">[video]</a></p>
											</div>
										</article>
										<article>
											<a href="https://arxiv.org/abs/1904.05916" class="image"><img src="images/synthetic.png" alt="" /></a>
											<div class="inner">
												<p><b>Synthetic Examples Improve Generalization for Rare Classes</b><br>
												<b>Sara Beery</b>, Yang Liu, Dan Morris, Jim Piavis, Ashish Kapoor, Markus Meister, Neel Joshi, Pietro Perona<br>
												WACV 2020<br>
												<a href="https://arxiv.org/abs/1904.05916" target="_self">[paper]</a></p>
											</div>
										</article>
										<article>
											<a href="https://dl.acm.org/doi/fullHtml/10.1145/3466857" class="image"><img src="images/cameratraps.png" alt="" /></a>
											<div class="inner">
												<p><b>Efficient Pipeline for Camera Trap Image Review</b><br>
												   <b>Sara Beery</b>, Dan Morris, Siyu Yang<br>
												   Data Mining and AI for Conservation at KDD 2018 <b>(Selected to be featured at KDD Earth Day)</b><br>
											           <a href="https://arxiv.org/abs/1907.06772" target="_self">[paper]</a><a href="https://github.com/microsoft/CameraTraps/blob/master/megadetector.md" target="_self">[code]</a>
										                </p>
											</div>
										</article>
										<article>
											<a href="https://arxiv.org/abs/1807.04975" class="image"><img src="images/terra_incognita.png" alt="" /></a>
											<div class="inner">
												<p><b>Recognition in Terra Incognita</b><br>
												<b>Sara Beery</b>, Grant Van Horn, Pietro Perona<br>
												ECCV 2018<br>
												<a href="https://arxiv.org/abs/1807.04975" target="_self">[paper]</a><a href="https://beerys.github.io/CaltechCameraTraps/" target="_self">[data]</a></p>
											</div>
										</article>
										<article>
											<a href="https://ieeexplore.ieee.org/document/7532575" class="image"><img src="images/motion.png" alt="" /></a>
											<div class="inner">
												<p><b>Finding Areas of Motion in Camera Trap Images</b><br>
												Agnieszka Miguel, <b>Sara Beery</b>, Erica Flores, Loren Klemesrud<br>
												IEEE ICIP 2016<br>
												<a href="https://ieeexplore.ieee.org/document/7532575" target="_self">[paper]</a></p>
											</div>
										</article>
										
									</div>
<!-- 									<h4>Workshop Publications</h4>
								        <div class="features">
										<article>
											<a href="https://arxiv.org/abs/2105.03494" class="image"><img src="images/iwildcam2021.jpeg" alt="" /></a>
											<div class="inner">
												<p><b>The iWildCam 2021 Competition Dataset</b><br>
												<b>Sara Beery</b>, Arushi Agarwal, Elijah Cole, Vighnesh Birodkar<br>
												FGVC8 at CVPR 2021<br>
												<a href="https://arxiv.org/abs/2105.03494" target="_self">[paper]</a><a href="https://github.com/visipedia/iwildcam_comp" target="_self">[data]</a><a href="https://www.kaggle.com/c/iwildcam2021-fgvc8" target="_self">[kaggle]</a></p>
											</div>
										</article>
										<article>
											<a href="https://arxiv.org/abs/2004.10340" class="image"><img src="images/iwildcam2021.jpeg" alt="" /></a>
											<div class="inner">
												<p><b>The iWildCam 2020 Competition Dataset</b><br>
												<b>Sara Beery</b>, Elijah Cole, Arvi Gjoka<br>
												FGVC7 at CVPR 2020<br>
												<a href="https://arxiv.org/abs/2004.10340" target="_self">[paper]</a><a href="https://github.com/visipedia/iwildcam_comp/tree/master/2020" target="_self">[data]</a><a href="https://www.kaggle.com/c/iwildcam-2020-fgvc7" target="_self">[kaggle]</a></p>
											</div>
										</article>
										<article>
											<a href="https://arxiv.org/abs/1907.07617" class="image"><img src="images/iwildcam2021.jpeg" alt="" /></a>
											<div class="inner">
												<p><b>The iWildCam 2019 Challenge Dataset</b><br>
												<b>Sara Beery</b>, Dan Morris, Pietro Perona<br>
												FGVC6 at CVPR 2019<br>
												<a href="https://arxiv.org/abs/1907.07617" target="_self">[paper]</a><a href="https://github.com/visipedia/iwildcam_comp/tree/master/2019" target="_self">[data]</a><a href="https://www.kaggle.com/c/iwildcam-2019-fgvc6" target="_self">[kaggle]</a></p>
											</div>
										</article>
										<article>
											<a href="https://arxiv.org/abs/1904.05986" class="image"><img src="images/iwildcam2021.jpeg" alt="" /></a>
											<div class="inner">
												<p><b>The iWildCam 2018 Challenge Dataset</b><br>
												<b>Sara Beery</b>, Grant van Horn, Oisin Mac Aodha, Pietro Perona<br>
												FGVC5 at CVPR 2018<br>
												<a href="https://arxiv.org/abs/1904.05986" target="_self">[paper]</a><a href="https://github.com/visipedia/iwildcam_comp/tree/master/2018" target="_self">[data]</a><a href="https://www.kaggle.com/c/iwildcam2018" target="_self">[kaggle]</a></p>
											</div>
										</article> -->
<!-- 								        </div> -->
								</div>
							</section>


		<!-- Talks -->
						
						        <section id="publications">
								<div class="container">
									<h3>Publications</h3>
<!--									<p><b>For a full list of publications please see my <a href="#cv" target="_self">CV</a> or <a href="https://scholar.google.com/citations?user=Hbr4c10AAAAJ&hl=en&oi=ao" target="_self">Google Scholar</a>.</b> </br>-->
<!--									* denotes equal contribution </p>-->

									<h4><u>Publications & Patents</u></h4>
									        <ul>
											<li><b><u>Fei Dou</u></b>, Jin Lu, Tingyang Xu, Chun-Hsi Huang, and Jinbo Bi, “A Bisection Reinforcement Learning Approach to 3-D Indoor Localization.”,
												IEEE Internet of Things Journal (IOT-J) 8, no. 8 (2021): 6519-6535. (<b>Impact Factor: 10.238</b>)</li>
											<li><b><u>Fei Dou</u></b>, Jin Lu, Zigeng Wang, Xia Xiao, Jinbo Bi, Chun-Hsi Huang, “Top-Down Indoor Localization with Wi-Fi Fingerprints using Deep Q-Network.”,
												In 2018 IEEE 15th International Conference on Mobile Ad Hoc and Sensor Systems (MASS), pp. 166-174. IEEE, 2018. (<b>Accept Ratio: 28%</b>)</li>
											<li>Jin Lu, <b><u>Fei Dou</u></b>, Chun-Hsi Huang, “Bi-Subspace Saliency Detection.”,
												In 2017 IEEE 7th Annual Computing and Communication Workshop and Conference (CCWC), pp. 1-7. IEEE, 2017.</li>
											<li>Martin, Robert, Yibo Zhu, Lina Pu, <b><u>Fei Dou</u></b>, Zheng Peng, Jun-Hong Cui, and Sanguthevar Rajasekaran, “Aqua-Sim Next Generation: A NS-3 based Simulator for
												Underwater Sensor Networks.” In Proceedings of the 10th International Conference on Underwater Networks & Systems (WuWNet), pp. 1-2. 2015.</li>
											<li><b><u>Fei Dou</u></b>, Zheng Peng, “On-demand Pipelined MAC for Multi-hop Underwater Wireless Sensor Networks.”,
												In Proceedings of the 10th International Conference on Underwater Networks & Systems (WuWNet), pp. 1-5. 2015.</li>
											<li>Yishan Su, Zhigang Jin, <b><u>Fei Dou</u></b>, “The Multi-channel MAC Protocol for High Performance Underwater Sensor Networks.”,
												Journal of Harbin Engineering University. 36, no. 7 (2015): 987-991.</li>
											<li>Yishan Su, Zhigang Jin, Zixin Liu, <b><u>Fei Dou*</u></b>, “Motion Prediction Based MAC for Underwater Wireless Sensor Networks.”,
												Journal of Electronics & Information Technology. 35, no. 3 (2013): 728-734.</li>
											<li><b><u>Fei Dou</u></b>, Zhigang Jin, Yao Zhang, Yishan Su, “A High Performance Multi-Channel MAC Protocol for Underwater Wireless Sensor Networks.”,
												In Proceedings of the 7th China Conference on Wireless Sensor Network (CWSN), pp. 1-11, 2013.</li>
											<li><b><u>Fei Dou</u></b>, Zhigang Jin, Yishan Su, Jian Liu, “WSF-MAC: A Weight-based Spatially Fair MAC Protocol for Underwater Sensor Networks.”,
												In 2012 2nd International Conference on Consumer Electronics, Communications and Networks (CECNet), pp. 3708-3711. IEEE, 2012.</li>
											<li>Jian Liu, Fangmin Li, <b><u>Fei Dou</u></b>, et al, “An Adaptive Cross-layer Mechanism of Multi-Channel Multi- Interface Wireless Networks for Real-Time Video Streaming.”,
												In 2010 7th International Conference on Ubiquitous Intelligence & Computing and 7th International Conference on Autonomic & Trusted Computing, pp. 165-170. IEEE, 2010.</li>
											<li>Zhigang Jin, Zixin Liu, <b><u>Fei Dou</u></b>, “Nodes Distribution Method Aiming at Improving the Fairness for Underwater Acoustic 3D Sensor Networks”, Patent, CN103095382B.</li>
											<li>Zhigang Jin, <b><u>Fei Dou</u></b>, Yishan Su, “Spatially Fair Media Access Control Method for Underwater Sensor Networks”, Patent, CN102612091B.</li>
										</ul>

									<h4><u> Working Papers </u></h4>
									        <ul>
											<li><b><u>Fei Dou</u></b>, Jin Lu, Tan Zhu, Jinbo Bi, “On-device Indoor Positioning: A Federated Reinforcement Learning Approach with Heterogeneous Devices.”,
												(<i><b>Under Review</b></i> by IEEE Internet of Things Journal (IOT-J))</li>
											<li>Sahibzada Umair, <b><u>Fei Dou</u></b>, Tughrul Arslan, “A Smart Narrow Down Approach based on Machine Learning for Indoor localization.”,
												(<i><b>Under Review</b></i> by IEEE Internet of Things Journal (IOT-J))</li>
											<li>Ziba Parsons, <b><u>Fei Dou</u></b>, Houyi Du, Jin Lu, “RWSADMM: A Server-Free Federated Learning Approach via Random Walk Stochastic ADMM.”, (<i><b>Under Review</b></i> by ICML 2023)</li>
											<li>Tan Zhu, <b><u>Fei Dou</u></b>, Xinyu Wang, Jinbo Bi, “DDF-Net: A Deep Dense Forest Net to Learn Interaction Effects for Click-through Rate Prediction.”, (<i><b>Under Review</b></i> by IJCAI 2023)</li>
											<li>Qinqing Liu, <b><u>Fei Dou</u></b>, Jinbo Bi, “Customized Positional Encoding with Side Information: A Robust Representation Learner for Crop Yield Prediction.”, (<i><b>Under Review</b></i> by IJCAI 2023)</li>
											<li><b><u>Fei Dou</u></b>, Cameron Cianci, Jinbo Bi, “Latent Orthonormal Contrastive Learning in Disaster Damage Assessment Using Paired Remote Sensing Imagery.”, (<i><b>In Submission</b></i> to ICCV 2023)</li>
											<li>Tan Zhu, <b><u>Fei Dou</u></b>, Chloe Becquey, Jinbo Bi, “Identifying Interactions among Categorical Predictors with Monte-Carlo Tree Search.”,
												(In Preparation, <a href="https://openreview.net/pdf?id=3aZMdP1BdSm">Preprint Version</a> Available Online</li>
											</ul>

  								</div>
							</section>
						
						<!-- Teaching -->
						
						        <section id="teaching">
								<div class="container">
									<h3>Teaching</h3>
									<h4>Summer School in Computer Vision Methods for Ecology</h4>
																			
									<p>In Summer 2022 I will be directing the first annual Resnick Sustainability Institute Summer School on Computer Vision Methods for Ecology <a href="https://cv4ecology.caltech.edu/" target="_self">(https://cv4ecology.caltech.edu/)</a>. This intensive, three-week program will teach applied computer vision methods to senior ecology graduate students and postdocs.</p>
									<p>Students will develop hands-on computer vision systems to help answer their own ecological research questions, using their own data. They will receive daily mentorship from a passionate team of computer vision experts with a track record of impact in conservation and sustainability. Each student will be provided with $2500 in cloud credits to facilitate their project development sponsored by Microsoft AI for Earth and Amazon AWS. </p>
									<p>Our team of instructors will work with applicants leading up to the intensive to curate computer-vision-ready labels for their data that will be used to prototype systems for their research questions during the class. Students will leave the course empowered to build their own computer vision models for ecological applications, and gain skills in problem formulation, dataset curation, model training, model evaluation, and hosting models for inference. </p>
								        
									<h4>Co-Instructor, Caltech EE/CS/CNS 148b - Advanced Topics in Computer Vision, Spring 2021</h4>
									<p>I helped adapt this advanced projects-based computer vision course to focus on conservation and sustainability applications. To set up project groups for success, I curated a set of ecological challenges with publicly available image and video datasets and matched projects to NGOs and research groups that would directly benefit to provide domain expertise and context. I mentored 5 teams of computer vision students in structuring and defining these real-world challenges as computer vision and machine learning problems, and assisted them in holistically probing and evaluating their solutions and effectively communicating them to both computer vision and machine learning experts and the ecological community.</p>
  								
									<h4>Guest Lectures and Tutorials</h4>
									<ul>
										<li>Lecture at Caltech Ge/Bi/BE/CNS/ESE147: Quantitative Ecology, 2022</li>
										<li>Lecture at Caltech Bi 1: Principles of Biology, 2022</li>
										<li>Tutorial at 2D3DAI, 2021</li>
										<li>Lecture at Georgia Tech VIP-4601 VVS: HumaniTech, 2020</li>
										<li>Lecture at Georgia Tech VIP-4601 VWE: GaTech4Wildlife, 2020</li>
										<li>Tutorial at CompSust Doctoral Consortium, 2020</li>
										<li>Tutorial at WILDLABS Tech Tutors, 2020</li>
										<li>Lecture at Caltech EE/CNS/CS 148: Advanced Topics in Computer Vision, 2020</li>
									</ul>
								</div>
							</section>

						<!-- Talks -->

						        <section id="talks">
								<div class="container">
									<h3>Selected Invited Talks</h3>

										<h4></h4>
										<ul>
											<li>University of Michigan-Dearborn, Invited Talk, ”Special Topic on Reinforcement Learning and its Applications”, Dearborn, Michigan, 2022</li>
											<li>IEEE International Conference on Mobile Ad Hoc and Sensor Systems (MASS), ”Hierarchical Indoor Localization Using Deep Q-Network”, Chengdu, China, 2018</li>
											<li>Seventh China Conference on Wireless Sensor Network (CWSN), ”Multi-Channel MAC Protocol for Underwater Wireless Sensor Networks”, Qingdao, China, 2013</li>
											<li>Qinghai Normal University, Invited Talk, ”Spatial Fairness in MAC Protocol for Underwater Sensor Network”, Xining, China, 2012</li>
											<li>Second International Conference on Consumer Electronic, Communications and Networks, ”A Weight-based Spatially Fair MAC Protocol for Underwater Sensor Network”, Three Gorges, China, 2012</li>
										</ul>
<!--									        <h4>Edge AI for Wildlife Conservation</h4>-->
<!--										<ul>-->
<!--											<li>AJCAI Edge AI Workshop, 2022</li>-->
<!--										</ul>-->
<!--									        <h4>Joint Human-AI Elephant Population Monitoring - A Case Study in the Greater Mara Ecosystem</h4>-->
<!--										<ul>-->
<!--											<li>Keynote - The Second CV4Animals Workshop at CVPR, 2022</li>-->
<!--										</ul>-->
<!--										<h4>Beyond Benchmarks - Going from Competition-Winning Methods to Real-World Solutions</h4>-->
<!--										<ul>-->
<!--											<li>LifeCLEF, 2021</li>-->
<!--											<li>Queer in AI at ICML, 2021</li>-->
<!--										</ul>-->
<!--										<h4>AI-Assisted Biodiversity Monitoring</h4>-->
<!--										<ul>-->
<!--											<li>Data Science Frontiers Seminar at the African Institute for Mathematical Sciences, 2021</li>-->
<!--											<li>Leveraging AI to Extend Specimen Networks at iDigBio, 2021</li>-->
<!--											<li>Princeton AI4All, 2021</li>-->
<!--										</ul>-->
<!--										<h4>Computer Vision for Biodiversity Monitoring and Conservation</h4>-->
<!--										<ul>-->
<!--											<li>EPFL Joint Mathis Lab Seminar, 2021</li>-->
<!--											<li>AI for Mankind, 2021</li>-->
<!--											<li>Yale Center for Biodiversity and Global Change Seminar, 2020</li>-->
<!--										</ul>-->
<!--										<h4>Deep Learning + Camera Traps</h4>-->
<!--										<ul>-->
<!--											<li>Plenary at Imaginecology Workshop (Deep Learning pour le traitement et l’analyse d’imageset de sons en écologie) at Le GDR EcoStat, 2020</li>-->
<!--										</ul>-->
<!--										<h4>Improving Computer Vision for Camera Traps: Leveraging Practitioner Insight to Build Solutions for Real-World Challenges</h4>-->
<!--										<ul>-->
<!--											<li>Ecological Society of America Annual Meeting, 2020</li>-->
<!--											<li>CompSust Open Graduate Seminar, 2020</li>-->
<!--											<li>Camera Trap Technology Symposium, 2019</li>-->
<!--										</ul>-->
<!--										<h4>AI for Camera Traps - Challenges, Best Practices, Benchmarks, and De-Siloing Data</h4>-->
<!--										<ul>-->
<!--											<li>World Agroforestry Centre (ICRAF) Seminar, 2020</li>-->
<!--											<li>WILDLABS Virtual Meetup on Camera Trapping, 2019</li>-->
<!--											<li>Computer Vision for Wildlife Conservation Workshop at ICCV, 2019</li>-->
<!--										</ul>-->
<!--										<h4>Computer Vision for Camera Traps</h4>-->
<!--										<ul>-->
<!--											<li>Caltech AI4Science Workshop, 2019</li>-->
<!--											<li>USC Center for AI in Society Symposium on AI for Conservation, 2019</li>-->
<!--											<li>Research Seminar at Google Venice, 2019</li>-->
<!--										</ul>	-->


  								</div>
							</section>
						
						<!-- CV -->
						
						        <section id="cv">
								<div class="container">
									<h3>CV & Bio</h3>
									<p>Download my CV <a href="assets/Sara_Beery_Academic_CV.pdf" download="Sara_Beery_CV.pdf">here</a>. Last updated September 2022.</p>
									
									<p><b>Bio for invited talks</b></p>
									<p>Sara Beery will join MIT as an assistant professor in the Faculty of Artificial Intelligence and Decision-Making in EECS in September 2023. Beery received her PhD in computing and mathematical sciences at Caltech in 2022, where she was advised by Pietro Perona. Her research focuses on building computer vision methods that enable global-scale environmental and biodiversity monitoring across data modalities, tackling real-world challenges including strong spatiotemporal correlations, imperfect data quality, fine-grained categories, and long-tailed distributions. She partners with nongovernmental organizations and government agencies to deploy her methods in the wild worldwide and works toward increasing the diversity and accessibility of academic research in artificial intelligence through interdisciplinary capacity building and education.
									</p>


																			
										
  								</div>
							</section>
						
<!--						&lt;!&ndash; AI for Conservation Slack &ndash;&gt;-->
<!--						-->
<!--						        <section id="slack">-->
<!--								<div class="container">-->
<!--									<h3>AI for Conservation Slack</h3>-->
<!--																			-->
<!--									<p>In Fall of 2019 I started a Slack channel on AI for Conservation, to provide a shared, interdisciplinary space for researchers who work across the fields of computer vision, machine learning, and AI for conservation and sustainability applications to share opportunities, discuss best practices, and find collaborators. Now our community is over 1000 strong, with researchers from all over the globe. If you'd like to join us, just email <a href="mailto:aiforconservation@gmail.com" target="_self">(aiforconservation@gmail.com)</a></p>-->
<!--										-->
<!--  								</div>-->
<!--								<div class="image main" data-position="center">-->
<!--									<img src="images/sara_field_work_mep.jpg" alt="" />-->
<!--								</div>-->
<!--							</section>-->


						<!-- Five -->
						<!--
							<section id="five">
								<div class="container">
									<h3>Elements</h3>

									<section>
										<h4>Text</h4>
										<p>This is <b>bold</b> and this is <strong>strong</strong>. This is <i>italic</i> and this is <em>emphasized</em>.
										This is <sup>superscript</sup> text and this is <sub>subscript</sub> text.
										This is <u>underlined</u> and this is code: <code>for (;;) { ... }</code>. Finally, <a href="#">this is a link</a>.</p>
										<hr />
										<header>
											<h4>Heading with a Subtitle</h4>
											<p>Lorem ipsum dolor sit amet nullam id egestas urna aliquam</p>
										</header>
										<p>Nunc lacinia ante nunc ac lobortis. Interdum adipiscing gravida odio porttitor sem non mi integer non faucibus ornare mi ut ante amet placerat aliquet. Volutpat eu sed ante lacinia sapien lorem accumsan varius montes viverra nibh in adipiscing blandit tempus accumsan.</p>
										<header>
											<h5>Heading with a Subtitle</h5>
											<p>Lorem ipsum dolor sit amet nullam id egestas urna aliquam</p>
										</header>
										<p>Nunc lacinia ante nunc ac lobortis. Interdum adipiscing gravida odio porttitor sem non mi integer non faucibus ornare mi ut ante amet placerat aliquet. Volutpat eu sed ante lacinia sapien lorem accumsan varius montes viverra nibh in adipiscing blandit tempus accumsan.</p>
										<hr />
										<h2>Heading Level 2</h2>
										<h3>Heading Level 3</h3>
										<h4>Heading Level 4</h4>
										<h5>Heading Level 5</h5>
										<h6>Heading Level 6</h6>
										<hr />
										<h5>Blockquote</h5>
										<blockquote>Fringilla nisl. Donec accumsan interdum nisi, quis tincidunt felis sagittis eget tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan faucibus. Vestibulum ante ipsum primis in faucibus lorem ipsum dolor sit amet nullam adipiscing eu felis.</blockquote>
										<h5>Preformatted</h5>
										<pre><code>i = 0;

while (!deck.isInOrder()) {
    print 'Iteration ' + i;
    deck.shuffle();
    i++;
}

print 'It took ' + i + ' iterations to sort the deck.';</code></pre>
									</section>

									<section>
										<h4>Lists</h4>
										<div class="row">
											<div class="col-6 col-12-xsmall">
												<h5>Unordered</h5>
												<ul>
													<li>Dolor pulvinar etiam magna etiam.</li>
													<li>Sagittis adipiscing lorem eleifend.</li>
													<li>Felis enim feugiat dolore viverra.</li>
												</ul>
												<h5>Alternate</h5>
												<ul class="alt">
													<li>Dolor pulvinar etiam magna etiam.</li>
													<li>Sagittis adipiscing lorem eleifend.</li>
													<li>Felis enim feugiat dolore viverra.</li>
												</ul>
											</div>
											<div class="col-6 col-12-xsmall">
												<h5>Ordered</h5>
												<ol>
													<li>Dolor pulvinar etiam magna etiam.</li>
													<li>Etiam vel felis at lorem sed viverra.</li>
													<li>Felis enim feugiat dolore viverra.</li>
													<li>Dolor pulvinar etiam magna etiam.</li>
													<li>Etiam vel felis at lorem sed viverra.</li>
													<li>Felis enim feugiat dolore viverra.</li>
												</ol>
												<h5>Icons</h5>
												<ul class="icons">
													<li><a href="#" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
													<li><a href="#" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
													<li><a href="#" class="icon brands fa-instagram"><span class="label">Instagram</span></a></li>
													<li><a href="#" class="icon brands fa-github"><span class="label">Github</span></a></li>
													<li><a href="#" class="icon brands fa-dribbble"><span class="label">Dribbble</span></a></li>
													<li><a href="#" class="icon brands fa-tumblr"><span class="label">Tumblr</span></a></li>
												</ul>
											</div>
										</div>
										<h5>Actions</h5>
										<ul class="actions">
											<li><a href="#" class="button primary">Default</a></li>
											<li><a href="#" class="button">Default</a></li>
											<li><a href="#" class="button alt">Default</a></li>
										</ul>
										<ul class="actions small">
											<li><a href="#" class="button primary small">Small</a></li>
											<li><a href="#" class="button small">Small</a></li>
											<li><a href="#" class="button alt small">Small</a></li>
										</ul>
										<div class="row">
											<div class="col-3 col-6-medium col-12-xsmall">
												<ul class="actions stacked">
													<li><a href="#" class="button primary">Default</a></li>
													<li><a href="#" class="button">Default</a></li>
													<li><a href="#" class="button alt">Default</a></li>
												</ul>
											</div>
											<div class="col-3 col-6 col-12-xsmall">
												<ul class="actions stacked">
													<li><a href="#" class="button primary small">Small</a></li>
													<li><a href="#" class="button small">Small</a></li>
													<li><a href="#" class="button alt small">Small</a></li>
												</ul>
											</div>
											<div class="col-3 col-6-medium col-12-xsmall">
												<ul class="actions stacked">
													<li><a href="#" class="button primary fit">Default</a></li>
													<li><a href="#" class="button fit">Default</a></li>
													<li><a href="#" class="button alt fit">Default</a></li>
												</ul>
											</div>
											<div class="col-3 col-6-medium col-12-xsmall">
												<ul class="actions stacked">
													<li><a href="#" class="button primary small fit">Small</a></li>
													<li><a href="#" class="button small fit">Small</a></li>
													<li><a href="#" class="button alt small fit">Small</a></li>
												</ul>
											</div>
										</div>
									</section>

									<section>
										<h4>Table</h4>
										<h5>Default</h5>
										<div class="table-wrapper">
											<table>
												<thead>
													<tr>
														<th>Name</th>
														<th>Description</th>
														<th>Price</th>
													</tr>
												</thead>
												<tbody>
													<tr>
														<td>Item One</td>
														<td>Ante turpis integer aliquet porttitor.</td>
														<td>29.99</td>
													</tr>
													<tr>
														<td>Item Two</td>
														<td>Vis ac commodo adipiscing arcu aliquet.</td>
														<td>19.99</td>
													</tr>
													<tr>
														<td>Item Three</td>
														<td> Morbi faucibus arcu accumsan lorem.</td>
														<td>29.99</td>
													</tr>
													<tr>
														<td>Item Four</td>
														<td>Vitae integer tempus condimentum.</td>
														<td>19.99</td>
													</tr>
													<tr>
														<td>Item Five</td>
														<td>Ante turpis integer aliquet porttitor.</td>
														<td>29.99</td>
													</tr>
												</tbody>
												<tfoot>
													<tr>
														<td colspan="2"></td>
														<td>100.00</td>
													</tr>
												</tfoot>
											</table>
										</div>

										<h5>Alternate</h5>
										<div class="table-wrapper">
											<table class="alt">
												<thead>
													<tr>
														<th>Name</th>
														<th>Description</th>
														<th>Price</th>
													</tr>
												</thead>
												<tbody>
													<tr>
														<td>Item One</td>
														<td>Ante turpis integer aliquet porttitor.</td>
														<td>29.99</td>
													</tr>
													<tr>
														<td>Item Two</td>
														<td>Vis ac commodo adipiscing arcu aliquet.</td>
														<td>19.99</td>
													</tr>
													<tr>
														<td>Item Three</td>
														<td> Morbi faucibus arcu accumsan lorem.</td>
														<td>29.99</td>
													</tr>
													<tr>
														<td>Item Four</td>
														<td>Vitae integer tempus condimentum.</td>
														<td>19.99</td>
													</tr>
													<tr>
														<td>Item Five</td>
														<td>Ante turpis integer aliquet porttitor.</td>
														<td>29.99</td>
													</tr>
												</tbody>
												<tfoot>
													<tr>
														<td colspan="2"></td>
														<td>100.00</td>
													</tr>
												</tfoot>
											</table>
										</div>
									</section>

									<section>
										<h4>Buttons</h4>
										<ul class="actions">
											<li><a href="#" class="button primary">Primary</a></li>
											<li><a href="#" class="button">Default</a></li>
											<li><a href="#" class="button alt">Alternate</a></li>
										</ul>
										<ul class="actions">
											<li><a href="#" class="button primary large">Large</a></li>
											<li><a href="#" class="button">Default</a></li>
											<li><a href="#" class="button alt small">Small</a></li>
										</ul>
										<ul class="actions fit">
											<li><a href="#" class="button primary fit">Fit</a></li>
											<li><a href="#" class="button fit">Fit</a></li>
											<li><a href="#" class="button alt fit">Fit</a></li>
										</ul>
										<ul class="actions fit small">
											<li><a href="#" class="button primary fit small">Fit + Small</a></li>
											<li><a href="#" class="button fit small">Fit + Small</a></li>
											<li><a href="#" class="button alt fit small">Fit + Small</a></li>
										</ul>
										<ul class="actions">
											<li><a href="#" class="button primary icon solid fa-download">Icon</a></li>
											<li><a href="#" class="button icon solid fa-download">Icon</a></li>
											<li><a href="#" class="button alt icon solid fa-check">Icon</a></li>
										</ul>
										<ul class="actions">
											<li><span class="button primary disabled">Primary</span></li>
											<li><span class="button disabled">Default</span></li>
											<li><span class="button alt disabled">Alternate</span></li>
										</ul>
									</section>

									<section>
										<h4>Form</h4>
										<form method="post" action="#">
											<div class="row gtr-uniform">
												<div class="col-6 col-12-xsmall">
													<input type="text" name="demo-name" id="demo-name" value="" placeholder="Name" />
												</div>
												<div class="col-6 col-12-xsmall">
													<input type="email" name="demo-email" id="demo-email" value="" placeholder="Email" />
												</div>
												<div class="col-12">
													<select name="demo-category" id="demo-category">
														<option value="">- Category -</option>
														<option value="1">Manufacturing</option>
														<option value="1">Shipping</option>
														<option value="1">Administration</option>
														<option value="1">Human Resources</option>
													</select>
												</div>
												<div class="col-4 col-12-medium">
													<input type="radio" id="demo-priority-low" name="demo-priority" checked>
													<label for="demo-priority-low">Low Priority</label>
												</div>
												<div class="col-4 col-12-medium">
													<input type="radio" id="demo-priority-normal" name="demo-priority">
													<label for="demo-priority-normal">Normal Priority</label>
												</div>
												<div class="col-4 col-12-medium">
													<input type="radio" id="demo-priority-high" name="demo-priority">
													<label for="demo-priority-high">High Priority</label>
												</div>
												<div class="col-6 col-12-medium">
													<input type="checkbox" id="demo-copy" name="demo-copy">
													<label for="demo-copy">Email me a copy of this message</label>
												</div>
												<div class="col-6 col-12-medium">
													<input type="checkbox" id="demo-human" name="demo-human" checked>
													<label for="demo-human">I am a human and not a robot</label>
												</div>
												<div class="col-12">
													<textarea name="demo-message" id="demo-message" placeholder="Enter your message" rows="6"></textarea>
												</div>
												<div class="col-12">
													<ul class="actions">
														<li><input type="submit" value="Send Message" /></li>
														<li><input type="reset" value="Reset" class="alt" /></li>
													</ul>
												</div>
											</div>
										</form>
									</section>

									<section>
										<h4>Image</h4>
										<h5>Fit</h5>
										<span class="image fit"><img src="images/banner.jpg" alt="" /></span>
										<div class="box alt">
											<div class="row gtr-50 gtr-uniform">
												<div class="col-4"><span class="image fit"><img src="images/pic01.jpg" alt="" /></span></div>
												<div class="col-4"><span class="image fit"><img src="images/pic02.jpg" alt="" /></span></div>
												<div class="col-4"><span class="image fit"><img src="images/pic03.jpg" alt="" /></span></div>
												<div class="col-4"><span class="image fit"><img src="images/pic02.jpg" alt="" /></span></div>
												<div class="col-4"><span class="image fit"><img src="images/pic03.jpg" alt="" /></span></div>
												<div class="col-4"><span class="image fit"><img src="images/pic01.jpg" alt="" /></span></div>
												<div class="col-4"><span class="image fit"><img src="images/pic03.jpg" alt="" /></span></div>
												<div class="col-4"><span class="image fit"><img src="images/pic01.jpg" alt="" /></span></div>
												<div class="col-4"><span class="image fit"><img src="images/pic02.jpg" alt="" /></span></div>
											</div>
										</div>
										<h5>Left &amp; Right</h5>
										<p><span class="image left"><img src="images/avatar.jpg" alt="" /></span>Fringilla nisl. Donec accumsan interdum nisi, quis tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent. Donec accumsan interdum nisi, quis tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent.</p>
										<p><span class="image right"><img src="images/avatar.jpg" alt="" /></span>Fringilla nisl. Donec accumsan interdum nisi, quis tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent. Donec accumsan interdum nisi, quis tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent.</p>
									</section>

								</div>
							</section>
						-->

					</div>

				<!-- Footer -->
					<section id="footer">
						<div class="container">
							<ul class="copyright">
								<li>&copy; Sara Beery. All rights reserved.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
							</ul>
						</div>
					</section>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
